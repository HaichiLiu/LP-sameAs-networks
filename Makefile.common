# ------------------------------------------------
# Copyright (C) 2010 by Ryan N. Lichtenwalter
# Email: rlichtenwalter@gmail.com
# 
# This file is part of LPmade.
# LPmade is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version. LPmade is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details. You should have received a copy of the GNU General Public License along with LPmade. If not, see <http://www.gnu.org/licenses/>.
# ------------------------------------------------

#####
# The NEIGHBORHOODS variable controls the geodesic distances at which LPmade performs analysis and predictions. Targets affected by this variable include "sm", "classify", "imbalance", and "plots". In the "sm" and "classify" subdirectories, results will be placed in n$(NEIGHBORHOODS) folders (e.g. n2). Setting the variable to 0 will perform predictions across all neighborhoods placing results in files in n0.
#这个参数控制对距离多远的节点对产生连接,n=1时应该是没有意义的.另外,对于不同的n的取值,不同预测器的性能应该是不一样的,可以多遍历几个n的取值.
#定义为 geodesic distances或者是hop数,但是不同的n的取值连接对集合是否相交呢?取决于 geodesic distances的定义,如果节点对之间具有多条路径呢?
#####
NEIGHBORHOODS := 0
#根据imbalance给出的结果，可以知道，对于无向图n>=5时不存在连接了，对于有向图n>=6时，不存在连接，因此无法对太大的n进行sm或者plots等操作，因为没有任何正例

#####
# The PREDICTORS variable controls which link prediction methods from the link prediction library are used. Targets affected by this variable include "sm", "classify", and "plots". Currently, the specification of predictors and arguments has strict requirements. Consider the IDegree predictor, the degree of the source node in the prediction. This degree may either be considered in terms of in-edges or out-edges. To predict both, IDegree should be specified as IDegree_D. In directed networks, this will perform predictions IDegree_O and IDegree_I, using both in-edges and out-edges for predictions. In undirected networks, it will only perform one set of predictions since there is no concept of in-edges and out-edges. To perform predictions with only one set of edges in directed networks, you must explicitly remove IDegree_D from the top variable assignment and add IDegree_I or IDegree_O in the directed network conditional block. An example is shown in comments below with PropFlow. All predictor arguments must come after the specification of directionality (D/I/O) and all arguments must be separated form each other and form the predictor name by an underscore (_). The final block is for the addition of predictors that do not accept directionality. Currently this includes only PreferentialAttachment, which is explicitly set to use out-edges of source and in-edges of target in directed networks (degenerating to total degree of both nodes in undirected networks).
#一些预测器计算的连接集合,可以是出连接,也可以是入连接,如果要使用两个方向的,那么就要使用_D,否则就明确指定是_I还是_O.
#在有向网络中,在条件语句中指定D,就可以从两个方向上进行预测.
#预测器要明确指定后缀_D_I_O。仅有PA算法不需要,因为PA明确指定是出度乘以入度,不过当是无向网络时PA就不区分出入度了
#条件语句执行的结果是：如果是有向网络，那么每个预测器都生成两个，分别以_I和_O结尾
#如果是无向网络，那么预测器直接结尾，不带出入链标识
#对于无向网络，由于连接是双向表示的，那么其实在预测的时候，只需任意预测一个方向的即可
#但是对于区分源和目标节点的，取值还是会不一样的，到底I和J是如何实现的？？？
#####
PREDICTORS := 
ifeq ($(DIRECTED),1)
	PREDICTORS := $(shell echo $(PREDICTORS) | sed 's/_D$$/_I/; s/_D /_I /g; s/_D_/_I_/g') $(shell echo $(PREDICTORS) | sed 's/_D$$/_O/; s/_D /_O /g; s/_D_/_O_/g')
#	PREDICTORS := $(PREDICTORS) PropFlow_O_5
else
	PREDICTORS := $(shell echo $(PREDICTORS) | sed 's/_D$$//; s/_D / /g; s/_D_/_/g')
#	PREDICTORS := $(PREDICTORS) PropFlow_5
endif
#条件语句之后,又添加PA算法,因为PA算法无需双向计算
PREDICTORS := $(PREDICTORS) IDegree_O JDegree_I IPageRank_O_0.85 JPageRank_I_0.85 PreferentialAttachment
####################需要去掉的指标有：#######################
#语义上无意义的指标，应该去掉，ClusteringCoefficient_D 
#Distance The geodesic distance between the source and the target. This predictor is only useful in scenarios when the -c flag is provided to predict or when -n 0 is used. This predictor accepts no additional arguments.因此Distance指标也不需要，当n=0时，稍微有些意义
#############################################################
#######################是否考虑权重的指标#########################
#UnweightedPropFlow和PropFlow的区别是是否考虑边的权重，
#Degree和Volume指标也相当于是是否考虑了边权重
#WeightedRootedPageRank_D_0.15 RootedPageRank_D_0.15
#IDegree_D IVolume_D JDegree_D JVolume_D UnweightedPropFlow_D_7 PropFlow_D_7 RootedPageRank_D_0.15 WeightedRootedPageRank_D_0.15
#################################################################
#######################考虑目标还是源节点#########################
#对于节点度指标来说，应该使用源节点的出度，目标节点的入度，即IDegree_O, JDegree_I？但也不对，目标节点的出度大，也是一个好的指标？
#对于有向图，一些指标区分了源节点和目标节点，这些指标可能都是有意义的，都可以尝试
#对于无向图，由于不区分源节点和目标节点，那么连接是如何确定的呢？可能区别在于，无向图是用双向边表示的，那么对于无向图，在预测的时候，测试集中的连接也都是双向连接，那么是如何预测的呢？先暂时不考虑，仅考虑有向图吧
#########################################################
########################区分n=2时的指标###################
#基于共同邻居的指标，仅当n=2时，才有意义，因此仅在n=2时，才使用这些指标
#它们是：AdamicAdar_D CommonNeighbor_D JaccardCoefficient_D
#需要注意的是，仅当是无向图的时候，这些指标在n>=3的时候无法使用
#当是有向图的时候，是可以使用的
#########################################################
########################指标类型的区分####################
#基于公共邻居的：AdamicAdar_D CommonNeighbor_D JaccardCoefficient_D
#基于路径的（全局信息）：ShortestPathCount_D_7 Katz_D_7_0.05 RootedPageRank_D_0.15 UnweightedPropFlow_D_7 SimRank_D_0.8（其中最大路径根据网络直径设置）
#基于节点信息（度）（局部信息）的：IDegree_D JDegree_D IPageRank_D_0.85 JPageRank_D_0.85 PreferentialAttachment
#全部指标： AdamicAdar_D CommonNeighbor_D JaccardCoefficient_D IDegree_D JDegree_D IVolume_D JVolume_D IPageRank_D_0.85 JPageRank_D_0.85 RootedPageRank_D_0.15   Distance_D Katz_D_5_0.05 PropFlow_D_5 UnweightedPropFlow_D_5 SimRank_D_0.8 ShortestPathCount_D_5 
#########################################################
########################指标类型的区分：有向图####################
#基于公共邻居的：AdamicAdar_O CommonNeighbor_O JaccardCoefficient_O
#基于路径的（全局信息）：ShortestPathCount_O_7 Katz_O_7_0.05 RootedPageRank_O_0.15 UnweightedPropFlow_O_7 SimRank_O_0.8（其中最大路径根据网络直径设置）
#基于节点信息（度）（局部信息）的：IDegree_O JDegree_I IPageRank_O_0.85 JPageRank_I_0.85 PreferentialAttachment
#全部指标： AdamicAdar_D CommonNeighbor_D JaccardCoefficient_D IDegree_D JDegree_D IVolume_D JVolume_D IPageRank_D_0.85 JPageRank_D_0.85 RootedPageRank_D_0.15   Distance_D Katz_D_5_0.05 PropFlow_D_5 UnweightedPropFlow_D_5 SimRank_D_0.8 ShortestPathCount_D_5 
#########################################################
########################需要调优的指标####################
#IPageRank PageRank的参数d value
#Katz 第二个参数：β must be lower than the reciprocal of the largest eigenvalue of matrix A to ensure the convergence 值越小，效果越接近CN指标 
#SimRank [0, 1]区间的一个值 
#RootedPageRank 发射概率，[0,1]，the random walk restart parameter α.
#需要选择效果确实好的，有前途的进行调优
#########################################################

#####
# The features variable and assignments work the same was as the PREDICTORS variable and assignments described above. This variable affects only the "classify" target. The variable specifies that features that should be used in supervised classification of links.
#这里的特征集合需要根据情况，选择一些性能较好的预测器
#####
FEATURES := 
ifeq ($(DIRECTED),1)
	FEATURES := $(shell echo $(FEATURES) | sed 's/_D$$/_I/; s/_D /_I /g; s/_D_/_I_/g') $(shell echo $(FEATURES) | sed 's/_D$$/_O/; s/_D /_O /g; s/_D_/_O_/g')
else
	FEATURES := $(shell echo $(FEATURES) | sed 's/_D$$//; s/_D / /g; s/_D_/_/g')
endif
FEATURES := $(FEATURES) AdamicAdar_D CommonNeighbor_D JaccardCoefficient_D ShortestPathCount_D_7 Katz_D_7_0.05 RootedPageRank_D_0.15 UnweightedPropFlow_D_7 SimRank_D_0.8 PreferentialAttachment

####################不同n的特征集合不同 有向图####################
####################需要重新进行实验，对于有向图邻居指标是一直可以用的###############
#n=02 IDegree_O JDegree_I IPageRank_I_0.85 JPageRank_O_0.85 PreferentialAttachment AdamicAdar_O CommonNeighbor_O JaccardCoefficient_O ShortestPathCount_O_7 Katz_O_7_0.05 RootedPageRank_O_0.15 UnweightedPropFlow_O_7 SimRank_O_0.8 
#只选择特定方向的指标，因为它们效果更好
#n=3 ShortestPathCount_D_7 Katz_D_7_0.05 RootedPageRank_D_0.15 UnweightedPropFlow_D_7 SimRank_D_0.8 IDegree_D JDegree_D JPageRank_D_0.85 PreferentialAttachment IPageRank_J_0.85(不能正确执行)
#n=4 ShortestPathCount_D_7 Katz_D_7_0.05 RootedPageRank_D_0.15 UnweightedPropFlow_D_7 SimRank_D_0.8 IDegree_D PreferentialAttachment JDegree_I IPageRank_O_0.85 JPageRank_O_0.85 
#n=0 2时，所有指标都可以选择，n=34时，选择除了邻居指标之外的
#或者，根据n上不同指标的性能来选择，还要除去那些低于50%的指标
#有无权重指标必须调一个出来，而且最好是要么都有权重，要么都无权重
#n=02 Degree>Volume
#n=3 IDegree_O<IVolume_O之外，都是Degree>Volume
#n=4 Degree<Volume
#实际上Degree这个指标，是否考虑权重意义不大，就当都不考虑权重好了，其他指标也暂时不考虑权重了
#AUROC<50%的有：
#n=4 JDegree_O PropFlow_O_7 WeightedRootedPageRank_O_0.15
#n=3 IPageRank_I_0.85
#n=4 IPageRank_I_0.85 JDegree_O JPageRank_I_0.85
##########################################################
####################不同n的特征集合不同 无向图####################
#n=0 AdamicAdar_D CommonNeighbor_D JaccardCoefficient_D ShortestPathCount_D_7 Katz_D_7_0.05 RootedPageRank_D_0.15 UnweightedPropFlow_D_7 SimRank_D_0.8 PreferentialAttachment
#因为考虑只预测n=0时候的连接，因此选择所有指标
#n=2 AdamicAdar_D CommonNeighbor_D ShortestPathCount_D_7 Katz_D_7_0.05 RootedPageRank_D_0.15 UnweightedPropFlow_D_7 PreferentialAttachment
#n=3 ShortestPathCount_D_7 Katz_D_7_0.05 RootedPageRank_D_0.15 UnweightedPropFlow_D_7 SimRank_D_0.8 PreferentialAttachment
#n=4 UnweightedPropFlow_D_7 SimRank_D_0.8
#全部指标：AdamicAdar_D CommonNeighbor_D JaccardCoefficient_D ShortestPathCount_D_7 Katz_D_7_0.05 RootedPageRank_D_0.15 UnweightedPropFlow_D_7 SimRank_D_0.8 IDegree_D JDegree_D IPageRank_D_0.85 JPageRank_D_0.85 PreferentialAttachment
#AUROC<50%的有：
#n=2 JaccardCoefficient SimRank
#n=4 Katz PA RootedPageRank ShortestPathCount
##########################################################

#####
# This variable allows for link prediction using vertex collocation profile (VCP) computations. Select one or more of VCP3Undirected, VCP3Directed, VCP4Undirected, VCP4Directed.
#####
VCP := VCP3Undirected VCP4Undirected

#####
# This variable specifies the number of bags that should be used in constructing the supervised classifier. It only affects the "classify" target. Larger numbers lead to increasingly better performance but at higher computational cost and with decreasing gains. In line with the KDD paper "New Perspectives and Methods in Link Prediction" (Lichtenwalter 2010), we use 10 bags.
#更大的bag数可以提高效果，但是增加了计算开销。那么我应该对这个参数也进行调优，找一个较大的取指
#####
NUM_BAGS := 10

#####
# This variable only affects the "classify" target. Link prediction is inherently a very imbalanced domain with few possible links actually forming. In supervised classification, training sets are much more manageable when the high proportion of negative instances is decreased to allow for faster computation and increased focus on the class boundary region.
#####
PERCENT_POSITIVE := 10

#####
# This variable specifies the evaluation metrics to run on prediction outputs and, in some cases, the metrics for which to generate plots. It affects the "sm", "classify", "vcp", and "plots" target. Possible metrics are listed below:
# roc auroc pr aupr ef tnp 
#####
EVALUATION_METRICS := roc auroc pr aupr ef tnp

#####
# This specifies the maximum memory available to "sort". Increasing values may increase sorting speed. Sort will never exceed this amount of memory consumption instead dumping intermediate results to temporary files.
#####
SORT_MEMORY_MAX := 2G

#####
# This specifies the maximum memory available to the Java virtual machine when running WEKA. For very large data sets, tens of gigabytes may be required. WEKA will fail if it requires more memory than allowed, so it is safe to set this to physical memory divided by the number of tasks to speculatively run simultaneously in hopes that the memory is sufficient. The fastest way to discover the memory requirements of classification is to first set this to the maximum memory of your machine and to observe the maximum working set size of the WEKA classification process.
#####
WEKA_MEMORY_MAX := 2G

#####
# This target copies, downloads, or constructs source data depending on task-specific user specifications. If there is no specification for src, then there must be a subdirectory src in the task-specific directory that has the necessary source files.
#####
src: $(addprefix ./src/,$(SRC))

#####
# This makes the stream directory and places LPmade generic stream files in that directory based on the source data and PERIOD specifications inside the task-specific Makefile.
#根据src中的源文件和PERIOD说明,生成stream文件
#####
stream: $(addsuffix .txt.gz,$(addprefix ./stream/,$(PERIODS)))

#####
# This makes all possible networks, FEATURE, LABEL, UNSUPERVISED, TEST, and COMPLETE, based on the stream target output and the period settings inside the task-specific Makefile.
#根据stream的输出和period的设置,生成各种所需要的网络
#####
net: $(addsuffix .net,$(addprefix ./net/,FEATURE LABEL UNSUPERVISED TEST COMPLETE))

#####
# This is the target to compute single-metric unsupervised methods of link prediction. The methods computed are determined by the PREDICTORS variable above. Predictions occur within the NEIGHBORHOODS variable above.
#sm对所有的评价指标,对所有的邻居数,对所有的预测器进行三重循环预测
#####
sm: $(foreach m,$(EVALUATION_METRICS),$(addsuffix .$(m),$(addprefix ./sm/n,$(foreach n,$(NEIGHBORHOODS),$(addprefix $(n)/,$(foreach p,$(PREDICTORS),$(p)))))))

#####
# This is the target to compute supervised classification using bagging and undersampling parameters as specified in the variables above. The WEKA machine learning toolkit is used for its bagging and random forest classification algorithms, but power users may modify the classification rules to use whatever WEKA classifier they like.
#用bagging和undersampling这两个参数来计算有监督的分类器。用WEKA的bagging和random forest分类算法。
#####
classify: $(foreach m,$(EVALUATION_METRICS),$(addsuffix .$(m),$(addprefix ./classify/n,$(foreach n,$(NEIGHBORHOODS),$(addprefix $(n)/,result)))))

#####
# This target goes beyond simply outputting numbers describing results to instead using the included gnuplot distribution to provide comparative plots of predictor performance. It also provides analytical plots using binning to determine the efficacy of various predictors within their individual score output regions.
#为每个neighborhoods n画roc曲线,为每个n画pr曲线,为每个PREDICTORS p画ef曲线
#这条规则说明了要画的曲线类型,后面应该还有如何生成这些曲线的代码
#添加了$(addprefix ./plots/,$(foreach p,$(PREDICTORS),$(p)_tnp.eps))之后,发现,所有预测算法的tnp值画在了一张图上
#而且,重复出现了所有预测算法那么多次,这说明有错误,
#经检查发现,tnp图的生成是同pr和roc算法一样,针对所有预测器的,那么要生成tnp图,应该是对NEIGHBOR循环
#####
plots: $(addprefix ./plots/n,$(foreach n,$(NEIGHBORHOODS),$(n)_roc.eps)) $(addprefix ./plots/n,$(foreach n,$(NEIGHBORHOODS),$(n)_pr.eps)) $(addprefix ./plots/,$(foreach p,$(PREDICTORS),$(p)_ef.eps)) $(addprefix ./plots/n,$(foreach n,$(NEIGHBORHOODS),$(n)_tnp.eps))

#####
# This target computes network statistics on the COMPLETE network as specified in the task-specific Makefile.
#网络的统计特征分析
#####
stats: $(addprefix ./stats/,average_clustering_coefficient.txt free_choice_mutuality.txt scc_stats.txt out_degree_stats.txt pageranks.txt assortativity_coefficient.txt betweenness.txt clustering_coefficient_stats.txt clustering_spectrum.txt count_edges.txt count_mutuals.txt count_vertices.txt eccentricity_stats.txt pseudo_diameter.txt shortest_path_stats.txt wcc_stats.txt)

#####
# This target computes SCC information about network data with increasing edge thresholds and places it in a file in the threshold directory, which the target creates. Currently, the target is set to threshold edges from 1 to 15 where the number is the minimum weight required to maintain the edge in the thresholded network.
#####
threshold: $(addprefix ./threshold/,$(foreach t,1 2 3 4 5 6 7 8 9 10 11 12 13 14 15,$(t)_scc_stats.txt))

#####
# This target produces growth plots based on the PERIODS variables specified in the task-specific Makefile. These plots show the trend in various network characteristics with increasing observation time.
#####
growth: $(addprefix ./growth/,growth.eps)

#####
# This target shows the imbalance properties of the link prediction task across the neighborhoods specified in the NEIGHBORHOODS variable above.
#####
imbalance: $(addprefix ./imbalance/,imbalance.eps)

#####
# This target allows for link prediction using vertex collocation profile (VCP) computations.
#####
vcp: $(foreach m,$(EVALUATION_METRICS),$(foreach vcp,$(VCP),./$(vcp)/n2/result.$(m)))

#####
# This target is mostly for demonstration purposes. It will create a folder "params" into which it will place the result of a parameter search over the alpha parameter in the RootedPageRank and WeightedRootedPageRank predictors. This parameter search will be visible to the user in the form of plots produced by gnuplot on the computed data. This demonstration parameter search may be extended by users for parameter searches of other methods by examining the params target directly below as well as the upstream targets farther down in this Makefile.
#params目标,会生成预测器的图片,评价指标是auroc
#新增SimRank指标的调优,共需要修改三个地方,一是图片的生成,而是gpi数据的生成,三是遍历不同的参数
#现在的问题是现有的三个调优预测器不同的参数都对auroc没有影响,问题可能执行的预测算法的参数不同predict函数中，也可能是数据没有反应到图中，也就是auroc的求得跟排序没有挂钩
#再增加PropFlow的参数调优
#####
params: $(addprefix ./params/RootedPageRank/,RootedPageRank.eps) $(addprefix ./params/WeightedRootedPageRank/,WeightedRootedPageRank.eps)  $(addprefix ./params/SimRank/,SimRank.eps) $(addprefix ./params/PropFlow/,PropFlow.eps)

#####
# The following text contains the core of the architectural automation. It should not be adjusted unless you know exactly what your goal is and how to accomplish it.
#####

BAGS := $(shell echo {1..$(NUM_BAGS)})

#把src中的源文件,转换为net文件的方法是
#首先用脚本SRC2STREAM把src转换成stream,然后再用STREAM_TO_NETWORK转换成网络
STREAM_TO_NETWORK := stream_to_network -i "," 2 3
ifeq ($(WEIGHTED_STREAM),1)
	STREAM_TO_NETWORK := weighted_stream_to_network -i "," 2 3 4
endif

#修改了RootedPageRank和WeightedRootedPageRank图片数据的横坐标范围
#因为本身,遍历的时候就是以0.05间隔遍历的
#图片数据.gpi的生成是通过.dat,
./params/RootedPageRank/RootedPageRank.gpi: ./params/RootedPageRank/RootedPageRank.dat
	echo 'set datafile separator " "' > $@.tmp;
	echo 'set term postscript eps enhanced color size 4in,4in blacktext "Helvetica" 18' >> $@.tmp;
	echo 'set title noenhanced "Rooted PageRank"' >> $@.tmp;
	echo 'set key on inside top right vertical' >> $@.tmp;
	echo 'set xlabel "{/Symbol a}"' >> $@.tmp;
	echo 'set xrange [0:1]' >> $@.tmp;
	echo 'set xtics 0.05' >> $@.tmp;
	echo 'set ylabel "AUC Performance"' >> $@.tmp;
	echo 'set yrange [:1]' >> $@.tmp;
	echo 'set ytics 0.1' >> $@.tmp;
	echo 'plot "$<" using 1:2 notitle with linespoints' >> $@.tmp;
	mv $@.tmp $@;
	
./params/WeightedRootedPageRank/WeightedRootedPageRank.gpi: ./params/WeightedRootedPageRank/WeightedRootedPageRank.dat
	echo 'set datafile separator " "' > $@.tmp;
	echo 'set term postscript eps enhanced color size 4in,4in blacktext "Helvetica" 18' >> $@.tmp;
	echo 'set title noenhanced "Weighted Rooted PageRank"' >> $@.tmp;
	echo 'set key on inside top right vertical' >> $@.tmp;
	echo 'set xlabel "{/Symbol a}"' >> $@.tmp;
	echo 'set xrange [0:1]' >> $@.tmp;
	echo 'set xtics 0.05' >> $@.tmp;
	echo 'set ylabel "AUC Performance"' >> $@.tmp;
	echo 'set yrange [:1]' >> $@.tmp;
	echo 'set ytics 0.1' >> $@.tmp;
	echo 'plot "$<" using 1:2 notitle with linespoints' >> $@.tmp;
	mv $@.tmp $@;

#新增SimRank指标的调优
./params/SimRank/SimRank.gpi: ./params/SimRank/SimRank.dat
	echo 'set datafile separator " "' > $@.tmp;
	echo 'set term postscript eps enhanced color size 4in,4in blacktext "Helvetica" 18' >> $@.tmp;
	echo 'set title noenhanced "SimRank"' >> $@.tmp;
	echo 'set key on inside top right vertical' >> $@.tmp;
	echo 'set xlabel "{/Symbol a}"' >> $@.tmp;
	echo 'set xrange [0:1]' >> $@.tmp;
	echo 'set xtics 0.1' >> $@.tmp;
	echo 'set ylabel "AUC Performance"' >> $@.tmp;
	echo 'set yrange [:1]' >> $@.tmp;
	echo 'set ytics 0.1' >> $@.tmp;
	echo 'plot "$<" using 1:2 notitle with linespoints' >> $@.tmp;
	mv $@.tmp $@;

#新增PropFlow指标的调优
./params/PropFlow/PropFlow.gpi: ./params/PropFlow/PropFlow.dat
	echo 'set datafile separator " "' > $@.tmp;
	echo 'set term postscript eps enhanced color size 4in,4in blacktext "Helvetica" 18' >> $@.tmp;
	echo 'set title noenhanced "PropFlow"' >> $@.tmp;
	echo 'set key on inside top right vertical' >> $@.tmp;
	echo 'set xlabel "{/Symbol a}"' >> $@.tmp;
	echo 'set xrange [0:10]' >> $@.tmp;
	echo 'set xtics 0.1' >> $@.tmp;
	echo 'set ylabel "AUC Performance"' >> $@.tmp;
	echo 'set yrange [:1]' >> $@.tmp;
	echo 'set ytics 0.1' >> $@.tmp;
	echo 'plot "$<" using 1:2 notitle with linespoints' >> $@.tmp;
	mv $@.tmp $@;

#参数调优的方法是,遍历不同的参数,并进行评价
#predict -n 3 -f ./net/UNSUPERVISED.net WeightedRootedPageRank O 
#-n DISTANCE    Degree of neighborhood in which to predict -n 3表明预测要预测的邻居的度是3
#-f NETWORK     File containing the network in which to predict 表示要预测的网络是UNSUPERVISED.net
#O,大写的ou,表示???	
./params/WeightedRootedPageRank/WeightedRootedPageRank.dat: $(addprefix ./params/WeightedRootedPageRank/,$(foreach p,0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95,$(p).auroc))
	rm -f $@;
	$(foreach p,$^,/bin/echo -n "$(basename $(notdir $(p))) " >> $@; cat $(p) >> $@;)

./params/WeightedRootedPageRank/%.prob.gz: ./net/UNSUPERVISED.net ./net/TEST.net
	mkdir -p $(@D);
	$(BIN)/predict -n 3 -f ./net/UNSUPERVISED.net WeightedRootedPageRank O | $(BIN)/label_predictions ./net/TEST.net | gzip > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 -a $${PIPESTATUS[2]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

./params/RootedPageRank/RootedPageRank.dat: $(addprefix ./params/RootedPageRank/,$(foreach p,0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65 0.70 0.75 0.80 0.85 0.90 0.95,$(p).auroc))
	rm -f $@;
	$(foreach p,$^,/bin/echo -n "$(basename $(notdir $(p))) " >> $@; cat $(p) >> $@;)

./params/RootedPageRank/%.prob.gz: ./net/UNSUPERVISED.net ./net/TEST.net
	mkdir -p $(@D);
	$(BIN)/predict -n 0 -f ./net/UNSUPERVISED.net RootedPageRank O | $(BIN)/label_predictions ./net/TEST.net | gzip > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 -a $${PIPESTATUS[2]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

#新增SimRank指标的调优
./params/SimRank/SimRank.dat: $(addprefix ./params/SimRank/,$(foreach p,0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0,$(p).auroc))
	rm -f $@;
	$(foreach p,$^,/bin/echo -n "$(basename $(notdir $(p))) " >> $@; cat $(p) >> $@;)

./params/SimRank/%.prob.gz: ./net/UNSUPERVISED.net ./net/TEST.net
	mkdir -p $(@D);
	$(BIN)/predict -n 3 -f ./net/UNSUPERVISED.net SimRank O | $(BIN)/label_predictions ./net/TEST.net | gzip > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 -a $${PIPESTATUS[2]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

#新增PropFlow指标的调优
./params/PropFlow/PropFlow.dat: $(addprefix ./params/PropFlow/,$(foreach p,1 2 3 4 5 6 7 8 9 10,$(p).auroc))
	rm -f $@;
	$(foreach p,$^,/bin/echo -n "$(basename $(notdir $(p))) " >> $@; cat $(p) >> $@;)

./params/PropFlow/%.prob.gz: ./net/UNSUPERVISED.net ./net/TEST.net
	mkdir -p $(@D);
	$(BIN)/predict -n 3 -f ./net/UNSUPERVISED.net PropFlow O | $(BIN)/label_predictions ./net/TEST.net | gzip > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 -a $${PIPESTATUS[2]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

#.net文件的生成规则
#方法是：用stream中的PERIODS，执行STREAM_TO_NETWORK代码得到
./net/%.net: $(addsuffix .txt.gz,$(addprefix ./stream/,$(PERIODS)))
	mkdir -p $(@D);
	gunzip --stdout $(addsuffix .txt.gz,$(addprefix ./stream/,$($(basename $(@F))))) | $(BIN)/$(STREAM_TO_NETWORK) > $@.tmp;
	mv $@.tmp $@;

#prob.gz文件的生成规则,是根据无监督和测试网络生成的UNSUPERVISED.net TEST.net
#无监督网络是9个周期的连接，测试网络是1个周期的连接
#大概的方法是,用predict命令,具体语句是predict -n $(subst sm/n,,$(@D)) -f ./net/UNSUPERVISED.net $(shell echo $(basename $(basename $(@F))) 
#用预测器对UNSUPERVISED.net进行预测，得到每个样本对的打分，然后用label_predictions对测试集TEST.net打标签，进行测试
#-n表示邻居的度,是NEIGHBORHOOD,是根据创建的nx文件夹设置参数
./sm/%.prob.gz: ./net/UNSUPERVISED.net ./net/TEST.net
	mkdir -p $(@D);
	$(BIN)/predict -n $(subst sm/n,,$(@D)) -f ./net/UNSUPERVISED.net $(shell echo $(basename $(basename $(@F))) | grep -o '_\(I\|O\)\(_.*\|$$\)' | sed 's/^_\(I\).*/-d \1 /; s/^_\(O\).*/-d \1 /')$(shell echo $(basename $(basename $(@F))) | sed 's/_I_/_/; s/_O_/_/; s/_I$$//; s/_O$$//; s/_/ /g') | $(BIN)/label_predictions ./net/TEST.net | gzip > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 -a $${PIPESTATUS[2]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

./classify/n%/train.names: $(addprefix ./classify/features/n%/,$(foreach f,$(FEATURES),$(f).prob.gz))
	mkdir -p $(@D);
	echo '0,1' > $@.tmp;
	echo -e -n '$(subst \n ,\n,$(foreach f,$(FEATURES),$(f): continuous\n))' >> $@.tmp;
	mv $@.tmp $@;

./classify/n%/test.names: ./classify/n%/train.names
	cp $< $@;

#从./net/FEATURE.net ./net/LABEL.net中获取特征信息features/%.prob.gz
#类似于sm目标，根据8个周期的特征网络，和一个周期的标签网络
#在特征网络上运行预测算法，在标签网络上进行打分
./classify/features/%.prob.gz: ./net/FEATURE.net ./net/LABEL.net
	mkdir -p $(@D);
	$(BIN)/predict -n $(subst classify/features/n,,$(@D)) -f ./net/FEATURE.net $(shell echo $(basename $(basename $(@F))) | grep -o '_\(I\|O\)\(_.*\|$$\)' | sed 's/^_\(I\).*/-d \1 /; s/^_\(O\).*/-d \1 /')$(shell echo $(basename $(basename $(@F))) | sed 's/_I_/_/; s/_O_/_/; s/_I$$//; s/_O$$//; s/_/ /g') | $(BIN)/label_predictions ./net/LABEL.net | gzip > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 -a $${PIPESTATUS[2]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

#从上一步得到的特征文件features/%.prob.gz，构造训练数据train.data.gz
./classify/n%/train.data.gz: $(addprefix ./classify/features/n%/,$(foreach f,$(FEATURES),$(f).prob.gz))
	mkdir -p $(@D);
	pr -t -s',' -m $(foreach f,$^,<(< $(f) gunzip | cut -d ' ' -f 1)) <(< $< gunzip | cut -d ' ' -f 2) | gzip > $@.tmp;
	mv $@.tmp $@;

#测试文件的获得来自sm算法给出的预测.prob.gz，sm的.prob.gz是根据TEST.net得到的
./classify/n%/test.data.gz: $(addprefix ./sm/n%/,$(foreach f,$(FEATURES),$(f).prob.gz))
	mkdir -p $(@D);
	pr -t -s',' -m $(foreach f,$^,<(< $(f) gunzip | cut -d ' ' -f 1)) <(< $< gunzip | cut -d ' ' -f 2) | gzip > $@.tmp;
	mv $@.tmp $@;
	
define DISTANCE_TEMPLATE
./VCP%/n$(1)/train.data.gz: ./net/FEATURE.net ./net/LABEL.net
	mkdir -p $$(@D);
	pr -t -s',' -m <(($$(BIN)/predict -n $(1) -f ./net/FEATURE.net $$(shell basename $$$$(dirname $$(@D))) 3>&1 1>&2- 2>&3-) 2> /dev/null | cut -d ' ' -f3- | tr ' ' ',') <($$(BIN)/predict -n $(1) -f ./net/FEATURE.net One | $$(BIN)/label_predictions ./net/LABEL.net | cut -d ' ' -f 2) | gzip > $$@.tmp && \
	if [ $$$${PIPESTATUS[0]} -eq 0 -a $$$${PIPESTATUS[1]} -eq 0 ]; then mv $$@.tmp $$@; else exit 1; fi;

./VCP%/n$(1)/train.names: ./VCP%/n$(1)/train.data.gz
	< $$< gunzip | head -n 1 | awk -F ',' 'BEGIN {print "0,1";} {for(i=0;i<NF-1;i++){print "f"i": continuous";}}' > $$@.tmp;
	mv $$@.tmp $$@;

./VCP%/n$(1)/test.data.gz: ./net/UNSUPERVISED.net ./net/TEST.net
	mkdir -p $$(@D);
	pr -t -s',' -m <(($$(BIN)/predict -n $(1) -f ./net/UNSUPERVISED.net $$(shell basename $$$$(dirname $$(@D))) 3>&1 1>&2- 2>&3-) 2> /dev/null | cut -d ' ' -f3- | tr ' ' ',') <($$(BIN)/predict -n $(1) -f ./net/UNSUPERVISED.net One | $$(BIN)/label_predictions ./net/TEST.net | cut -d ' ' -f 2) | gzip > $$@.tmp && \
	if [ $$$${PIPESTATUS[0]} -eq 0 -a $$$${PIPESTATUS[1]} -eq 0 ]; then mv $$@.tmp $$@; else exit 1; fi;
	
./VCP%/n$(1)/test.names: ./VCP%/n$(1)/test.data.gz
	< $$< gunzip | head -n 1 | awk -F ',' 'BEGIN {print "0,1";} {for(i=0;i<NF-1;i++){print "f"i": continuous";}}' > $$@.tmp;
	mv $$@.tmp $$@;

endef
$(foreach distance,$(NEIGHBORHOODS),$(eval $(call DISTANCE_TEMPLATE,$(distance))))

define WEKA_TEMPLATE
%/result_$(1).names: %/train.names
	mkdir -p $$(@D);
	cp $$< $$@;

#每个result_X.data.gz文件，是根据train.data.gz通过随机抽取一定比例反例得来的
#这步就是bag操作
%/result_$(1).data.gz: %/train.data.gz
	all=$$$$(< $$< gunzip | wc -l) && \
	pos=$$$$(< $$< gunzip | grep -c "1$$$$") && \
	neg=$$$$(($$$$all-$$$$pos)) && \
	count=`awk 'BEGIN {print '$$$$pos'/($$(PERCENT_POSITIVE)/100)-'$$$$pos'}'` && \
	percent=`awk 'BEGIN {print '$$$$count'/'$$$$neg'}'` && \
	< $$< gunzip | awk 'BEGIN{srand($(1));} {if( $$$$0 ~ /1$$$$/ || ($$$$0 ~ /0$$$$/ && rand() < '$$$$percent') ) {print;}}' | gzip > $$@.tmp && \
	if [ $$$${PIPESTATUS[0]} -eq 0 -a $$$${PIPESTATUS[1]} -eq 0 -a $$$${PIPESTATUS[2]} -eq 0 ]; then mv $$@.tmp $$@; else exit 1; fi;

#使用WEKA的随机森林，从训练数据上进行训练，得到模型
#-I 10,这个参数可能是，树的数量是10
#设置为100，看看效果，发现对于数据集连接问题，影响并不大
%/result_$(1).model: %/result_$(1).names %/result_$(1).data.gz
	mkdir -p $$(@D);
	$(JAVA) -Xmx$(WEKA_MEMORY_MAX) -cp $(WEKA) weka.classifiers.trees.RandomForest \
			-d $$@.tmp \
			-t $$(@D)/result_$(1).names \
			-I 10 -K 0 -S $(1);
	mv $$@.tmp $$@;

#使用随机森林，用得到的训练模型，对测试数据进行预测
%/result_$(1).prob.gz: %/result_$(1).model %/test.names %/test.data.gz
	mkdir -p $$(@D);
	$(JAVA) -Xmx$(WEKA_MEMORY_MAX) -cp $(WEKA) weka.classifiers.trees.RandomForest \
			-l $$(@D)/result_$(1).model \
			-T $$(@D)/test.names \
			-p 0 -distribution \
			| gzip > $$@.tmp && \
	if [ $$$${PIPESTATUS[0]} -eq 0 -a $$$${PIPESTATUS[1]} -eq 0 ]; then mv $$@.tmp $$@; else exit 1; fi;

endef
$(foreach bag,$(BAGS),$(eval $(call WEKA_TEMPLATE,$(bag))))
#对每个bag进行遍历

#从每个bag中得到最终的预测结果result.prob.gz
%/result.prob.gz: $(foreach bag,$(BAGS),%/result_$(bag).prob.gz)
	mkdir -p $(@D);
	pr -t -s' ' -m $(foreach bag,$(BAGS),<(< $(@D)/result_$(bag).prob.gz gunzip | cut -d ' ' -f 1) ) <(< $(@D)/result_1.prob.gz gunzip | cut -d ' ' -f 2) | awk -F ' ' '{sum=0; for(i=1;i<=$(NUM_BAGS);i++){sum+=$$i} print sum/$(NUM_BAGS)" "$$NF;}' | gzip > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

#从预测文件.prob中,生成排序后的预测文件sprob的规则
%.sprob.gz: %.prob.gz
	< $< gunzip | sort -S $(SORT_MEMORY_MAX) -T $(TEMP) -k1gr | gzip > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 -a $${PIPESTATUS[2]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

#以下是一组,从排序后的预测文件sprob生成各种评价指标的规则
#需要调用metrics文件夹下的计算指标的程序
#这里面并没有包含mse hmeasure costcurve指标的计算规则
%.roc: %.sprob.gz
	all=`< $< gunzip | wc -l` && \
	pos=`< $< gunzip | grep -c "1$$"` && \
	neg=`echo "$$all-$$pos" | bc` && \
	< $< gunzip | $(METRICS)/roc $$neg $$pos | sed 's/\(.\...\)..../\1/g' | uniq > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 -a $${PIPESTATUS[2]} -eq 0 -a $${PIPESTATUS[3]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

%.pr: %.sprob.gz
	pos=`< $< gunzip | grep -c "1$$"` && \
	< $< gunzip | $(METRICS)/pr 1 $$pos | sed 's/\(.\...\)......./\1/g' | uniq > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 -a $${PIPESTATUS[2]} -eq 0 -a $${PIPESTATUS[3]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

%.auroc: %.sprob.gz
	< $< gunzip | $(METRICS)/$(subst .,,$(suffix $(@F))) > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

%.aupr: %.sprob.gz
	pos=$$(< $< gunzip | grep -c '1$$') && \
	< $< gunzip | $(METRICS)/$(subst .,,$(suffix $(@F))) 0.001 $$pos > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

%.tnp: %.sprob.gz
	all=`< $< gunzip | wc -l` && \
	< $< gunzip | $(METRICS)/topnprec $$all > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;
	
%.ef: %.sprob.gz
	all=`< $< gunzip | wc -l` && \
	< $< gunzip | $(METRICS)/$(subst .,,$(suffix $(@F))) 10 $$all > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

#Receiver Operating Characteristic Curve 生成roc曲线.gpi文件的方法,根据sm生成的.roc文件得到
#该gpi文件是gunplot要用到的设置参数
./plots/%_roc.gpi: $(addprefix ./sm/%/,$(foreach p,$(PREDICTORS),$(p).roc))
	mkdir -p plots;
	echo 'set datafile separator " "' > $@.tmp;
	echo 'set term postscript eps enhanced color size 4in,4in blacktext "Helvetica" 18' >> $@.tmp;
	echo 'set title noenhanced "$(notdir $(CURDIR)) $(subst _roc,,$(basename $(@F)))"' >> $@.tmp;
	echo 'set key on inside bottom right vertical' >> $@.tmp;
	echo 'set xlabel "False Positive Rate"' >> $@.tmp;
	echo 'set xrange [0:1]' >> $@.tmp;
	echo 'set xtics 0.1' >> $@.tmp;
	echo 'set ylabel "True Positive Rate"' >> $@.tmp;
	echo 'set yrange [0:1]' >> $@.tmp;
	echo 'set ytics 0.1' >> $@.tmp;
	echo 'plot x notitle with lines lt 2 linecolor 0 $(foreach p,$(PREDICTORS),,"sm/$(subst _roc,,$(basename $(@F)))/$(p).roc" using 1:2 title "$(subst _, ,$(p))" with linespoints)' >> $@.tmp;
	mv $@.tmp $@;

#Precision-Recall Curve精确度召回率曲线 生成pr.gpi的方法,根据sm的.pr生成	
#精确度召回率的曲线,对于连接预测问题,正例十分少,也需要调整横纵坐标值的范围
#猜测这个曲线的横纵坐标轴标题是错误的,现在的标题应该是ROC曲线的.而PR曲线的标题应该是精确度和召回率
#把横坐标范围也设定为[0,1]，因为在classify之后，发现有的能够在召回率大于50%之后，精确度取指不为1
./plots/%_pr.gpi: $(addprefix ./sm/%/,$(foreach p,$(PREDICTORS),$(p).pr))
	mkdir -p plots;
	echo 'set datafile separator " "' > $@.tmp;
	echo 'set term postscript eps enhanced color size 4in,4in blacktext "Helvetica" 18' >> $@.tmp;
	echo 'set title noenhanced "$(notdir $(CURDIR)) $(subst _pr,,$(basename $(@F)))"' >> $@.tmp;
	echo 'set key on inside bottom right vertical' >> $@.tmp;
	echo 'set xlabel "Recall"' >> $@.tmp;
	echo 'set xrange [0:1]' >> $@.tmp;
	echo 'set xtics 0.1' >> $@.tmp;
	echo 'set ylabel "Precision"' >> $@.tmp;
	echo 'set yrange [0:1]' >> $@.tmp;
	echo 'set ytics 0.1' >> $@.tmp;
	echo 'plot x notitle with lines lt 2 linecolor 0 $(foreach p,$(PREDICTORS),,"sm/$(subst _pr,,$(basename $(@F)))/$(p).pr" using 1:2 title "$(subst _, ,$(p))" with linespoints)' >> $@.tmp;
	mv $@.tmp $@;

#Top n Precision指标 生成tnp.gpi的方法,根据sm的.tnp生成
#tnp指标,同pr和roc一样,是对预测器进行遍历的,也就是说,会把图生成在一张图上
#这个指标的画图,横坐标粒度太粗,是以Top的百分比来划分的,实际上由于候选集太大,比例应该十分小才行
#因此,调整下面的x轴相关参数
#y轴，上限设定为1，而不是为空
./plots/%_tnp.gpi: $(addprefix ./sm/%/,$(foreach p,$(PREDICTORS),$(p).tnp))
	mkdir -p plots;
	echo 'set datafile separator " "' > $@.tmp;
	echo 'set term postscript eps enhanced color size 4in,4in blacktext "Helvetica" 18' >> $@.tmp;
	echo 'set title noenhanced "$(notdir $(CURDIR)) $(subst _tnp,,$(basename $(@F)))"' >> $@.tmp;
	echo 'set key on inside bottom right vertical' >> $@.tmp;
	echo 'set xlabel "Top-X Proportion"' >> $@.tmp;
	echo 'set xrange [0:0.001]' >> $@.tmp;
	echo 'set xtics 0.0002' >> $@.tmp;
	echo 'set yrange [0:1]' >> $@.tmp;
	echo 'set ylabel "Precision"' >> $@.tmp;
	echo 'plot x notitle with lines lt 2 linecolor 0 $(foreach p,$(PREDICTORS),,"sm/$(subst _tnp,,$(basename $(@F)))/$(p).tnp" using 1:2 title "$(subst _, ,$(p))" with linespoints)' >> $@.tmp;
	mv $@.tmp $@;

#EF指标 生成ef.gpi的方法,根据sm的.ef生成
#EF指标,对NEIGHBORHOODS遍历,那么每张图都会生成单独的表
#EF指标的横纵坐标不再指定范围和步长,而是用了log x这样的语句
./plots/%_ef.gpi: $(addprefix ./sm/n,$(foreach n,$(NEIGHBORHOODS),$(n)/%.ef))
	mkdir -p plots;
	echo 'set datafile separator " "' > $@.tmp;
	echo 'set term postscript eps enhanced color size 4in,4in blacktext "Helvetica" 18' >> $@.tmp;
	echo 'set title noenhanced "$(notdir $(CURDIR)) $(subst _ef,,$(basename $(@F)))"' >> $@.tmp;
	echo 'set key on inside bottom right vertical' >> $@.tmp;
	echo 'set xlabel "Score"' >> $@.tmp;
	echo 'set log x' >> $@.tmp;
	echo 'set ylabel "True Positive Rate"' >> $@.tmp;
	echo 'set log y' >> $@.tmp;
	echo 'plot 0 notitle $(foreach n,$(NEIGHBORHOODS),,"sm/n$(n)/$(subst _ef,,$(basename $(@F))).ef" using 1:2 title "$(subst _, ,n=$(n))" with linespoints)' >> $@.tmp;
	mv $@.tmp $@;

#不平衡性的计数信息是根据./net/UNSUPERVISED.net ./net/TEST.net来计算的
#计算方法是：用One这个预测器进行对不同的n进行预测
./imbalance/%.counts: ./net/UNSUPERVISED.net ./net/TEST.net
	mkdir -p imbalance;
	rm -f $(@D)/pipe$(basename $(@F));
	mkfifo $(@D)/pipe$(basename $(@F));
	(wc -l > $(@D)/$(basename $(@F)).all) < $(@D)/pipe$(basename $(@F)) &
	$(BIN)/predict -n $(basename $(@F)) -f ./net/UNSUPERVISED.net One O | $(BIN)/label_predictions ./net/TEST.net | tee $(@D)/pipe$(basename $(@F)) | grep -c "1$$" | cat > $(@D)/$(basename $(@F)).pos;
	/bin/echo -n '$(basename $(@F)) ' > $@.tmp;
	paste -d ' ' $(@D)/$(basename $(@F)).all $(@D)/$(basename $(@F)).pos >> $@.tmp;
	mv $@.tmp $@;
	rm -f $(@D)/pipe$(basename $(@F)) $(@D)/$(basename $(@F)).all $(@D)/$(basename $(@F)).pos

./imbalance/imbalance.dat: $(addprefix ./imbalance/,$(foreach n,$(NEIGHBORHOODS),$(n).counts))
	cat ./imbalance/* | awk -F ' ' '{if( $$3 > 0 ){print $$1" "$$2" "$$3" "$$2-$$3" "($$2-$$3)/$$3;}}' > $@.tmp;
	mv $@.tmp $@;

./imbalance/imbalance.gpi: ./imbalance/imbalance.dat
	mkdir -p imbalance;
	echo 'set datafile separator " "' > $@.tmp;
	echo 'set term postscript eps enhanced color size 4in,4in blacktext "Helvetica" 18' >> $@.tmp;
	echo 'set notitle' >> $@.tmp;
	echo 'set key on inside bottom center vertical' >> $@.tmp;
	echo 'set xlabel "Geodesic Distance"' >> $@.tmp;
	echo 'set xtics 1' >> $@.tmp;
	echo 'set logscale y' >> $@.tmp;
	echo 'set yrange [1:]' >> $@.tmp;
	echo 'set format y "10^{%L}"' >> $@.tmp;
	/bin/echo -n 'plot "$<" using 1:4 title "(-) Count" with linespoints, ' >> $@.tmp;
	/bin/echo -n '"$<" using 1:3 title "(+) Count" with linespoints, ' >> $@.tmp;
	echo '"$<" using 1:5 title "Imbalance Ratio" with linespoints' >> $@.tmp;
	mv $@.tmp $@;

#从gpi文件生成eps的方法
#gpi文件并不是图像数据文件，而是作为GNUPLOT参数的命令文件
%.eps: %.gpi
	< $< $(GNUPLOT) > $@.tmp;
	mv $@.tmp $@;

#获取统计信息的规则,主要方法是调用对应的bin
./stats/average_clustering_coefficient.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/average_clustering_coefficient > $@.tmp;
	mv $@.tmp $@;

./stats/free_choice_mutuality.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/free_choice_mutuality > $@.tmp;
	mv $@.tmp $@;

./stats/out_degree_distribution.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/out_degree_distribution > $@.tmp;
	mv $@.tmp $@;

./stats/scc_distribution.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/scc_distribution > $@.tmp;
	mv $@.tmp $@;

./stats/pageranks.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/pagerank 0.85 > $@.tmp;
	mv $@.tmp $@;

./stats/assortativity_coefficient.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/assortativity_coefficient > $@.tmp;
	mv $@.tmp $@;

#新增一些统计信息的生成
./stats/betweenness.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/betweenness > $@.tmp;
	mv $@.tmp $@;

./stats/clustering_coefficient_distribution.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/clustering_coefficient_distribution > $@.tmp;
	mv $@.tmp $@;

./stats/clustering_spectrum.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/clustering_spectrum > $@.tmp;
	mv $@.tmp $@;

./stats/count_edges.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/count_edges > $@.tmp;
	mv $@.tmp $@;

./stats/count_vertices.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/count_vertices > $@.tmp;
	mv $@.tmp $@;

./stats/count_mutuals.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/count_mutuals > $@.tmp;
	mv $@.tmp $@;

./stats/eccentricity_distribution.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/eccentricity_distribution > $@.tmp;
	mv $@.tmp $@;

./stats/pseudo_diameter.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/pseudo_diameter > $@.tmp;
	mv $@.tmp $@;

./stats/shortest_path_distribution.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/shortest_path_distribution > $@.tmp;
	mv $@.tmp $@;

./stats/wcc_distribution.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/wcc_distribution > $@.tmp;
	mv $@.tmp $@;

#stats.txt文件是从distribution.txt得来的
#具体方法是：1）遍历所有行，读入到一个数组array[NR]中，数组的共有distribution.txt那么多行，每行存储了这一行的取值，并且记录下总和保存在sum变量中，并排序
#2）再次遍历数组，并计算sumsq，sumsq表示
#3）打印：总行数，distribution.txt的最小值，中位数平均值，最大值，算数平均值sum/NR，标准差
%_stats.txt: %_distribution.txt
	mkdir -p $(@D);
	< $< sort -g | awk '{sum+=$$0; array[NR]=$$0} END{for(x=1;x<=NR;x++){sumsq+=((array[x]-(sum/NR))^2);} print NR" "array[1]" "(array[int((NR+1)/2)]+array[int((NR+2)/2)])/2" "array[NR]" "sum/NR" "sqrt(sumsq/NR);}' > $@.tmp;
	mv $@.tmp $@;

./threshold/%_scc_distribution.txt: ./net/COMPLETE.net
	mkdir -p $(@D);
	< $< $(BIN)/threshold_edges $(subst _scc_distribution.txt,,$(@F)) | $(BIN)/scc_distribution > $@.tmp;
	mv $@.tmp $@;

INDEX := 1
define SPAN_TEMPLATE
SPAN$(INDEX) := $(SPAN$(shell echo $$(($(INDEX)-1)))) $(1)
INDEX := $(shell echo $$(($(INDEX)+1)))
SPANS += SPAN$(INDEX)
endef
$(foreach period,$(PERIODS),$(eval $(call SPAN_TEMPLATE,$(period))))

define SPAN_NET_TEMPLATE
./growth/$(1).net: $(addsuffix .txt.gz,$(addprefix ./stream/,$($(1))))
	gunzip --stdout $$^ | $(BIN)/stream_to_network "," 2 3 > $$@.tmp && \
	if [ $$$${PIPESTATUS[0]} -eq 0 -a $$$${PIPESTATUS[1]} -eq 0 ]; then mv $$@.tmp $$@; else exit 1; fi;
endef
$(foreach span,$(SPANS),$(eval $(call SPAN_NET_TEMPLATE,$(span))))

define SPAN_STATS_TEMPLATE
./growth/$(1).stats: ./growth/$(1).net
	mkdir -p $$(@D);
	/bin/echo -n $$$$(< $$< $(BIN)/count_vertices)' ' > $$@.tmp;
	/bin/echo -n $$$$(< $$< $(BIN)/count_edges)' ' >> $$@.tmp;
	/bin/echo -n $$$$(< $$< $(BIN)/average_clustering_coefficient)' ' >> $$@.tmp;
	/bin/echo -n $$$$(< $$< $(BIN)/assortativity_coefficient)' ' >> $$@.tmp;
	/bin/echo -n $$$$(< $$< $(BIN)/scc_distribution | wc -l)' ' >> $$@.tmp;
	echo $$$$(< $$< $(BIN)/scc_distribution | awk -F ' ' 'BEGIN{MAX=-1} {if($$$$2>MAX){MAX=$$$$2;}} END{print MAX;}') >> $$@.tmp
	mv $$@.tmp $$@;
endef
$(foreach span,$(SPANS),$(eval $(call SPAN_STATS_TEMPLATE,$(span))))

./growth/growth.dat: $(addprefix ./growth/,$(foreach period,$(PERIODS),$(subst PERIOD,SPAN,$(period).stats)))
	cat $^ | awk -F ' ' '{for(c=1;c<=NF;c++){vector[NR,c]=$$c;}} END{for(r=1;r<=NR;r++){printf "%d",r;for(c=1;c<=NF;c++){printf " %f",vector[r,c]/vector[NR,c];}printf "\n";}}' > $@.tmp && \
	if [ $${PIPESTATUS[0]} -eq 0 -a $${PIPESTATUS[1]} -eq 0 ]; then mv $@.tmp $@; else exit 1; fi;

./growth/growth.gpi: ./growth/growth.dat
	echo 'set datafile separator " "' > $@.tmp;
	echo 'set term postscript eps enhanced color size 4in,4in blacktext "Helvetica" 18' >> $@.tmp;
	echo 'set title noenhanced "Network Growth Characteristics"' >> $@.tmp;
	echo 'set key on inside bottom right vertical' >> $@.tmp;
	echo 'set xlabel "Time (in equal-width periods)"' >> $@.tmp;
	echo 'set xrange [1:$(shell echo $$(($$(< $< wc -l)-1)))]' >> $@.tmp;
	echo 'set xtics 1' >> $@.tmp;
	echo 'set ylabel "Value Relative to Final Value"' >> $@.tmp;
	echo 'set yrange [0:2]' >> $@.tmp;
	echo 'set ytics 0.25' >> $@.tmp;
	/bin/echo -n 'plot "$<" using 1:2 notitle "Vertex Count" with points linecolor 1, ' >> $@.tmp;
	/bin/echo -n '"$<" using 1:2 title "Vertex Count" smooth csplines with lines linecolor 1, ' >> $@.tmp;
	/bin/echo -n '"$<" using 1:3 notitle "Edge Count" with points linecolor 2, ' >> $@.tmp;
	/bin/echo -n '"$<" using 1:3 title "Edge Count" smooth csplines with lines linecolor 2, ' >> $@.tmp;
	/bin/echo -n '"$<" using 1:4 notitle "Average Clustering Coefficient" with points linecolor 3, ' >> $@.tmp;
	/bin/echo -n '"$<" using 1:4 title "Average Clustering Coefficient" smooth csplines with lines linecolor 3, ' >> $@.tmp;
	/bin/echo -n '"$<" using 1:5 notitle "Assortativity Coefficient" with points linecolor 4, ' >> $@.tmp;
	/bin/echo -n '"$<" using 1:5 title "Assortativity Coefficient" smooth csplines with lines linecolor 4, ' >> $@.tmp;
	/bin/echo -n '"$<" using 1:6 notitle "Number of SCCs" with points linecolor 5, ' >> $@.tmp;
	/bin/echo -n '"$<" using 1:6 title "Number of SCCs" smooth csplines with lines linecolor 5, ' >> $@.tmp;
	/bin/echo -n '"$<" using 1:7 notitle "Size of LSCC" with points linecolor 6, ' >> $@.tmp;
	echo '"$<" using 1:7 title "Size of LSCC" smooth csplines with lines linecolor 6' >> $@.tmp;
	mv $@.tmp $@;

.SECONDARY:
.PHONY: clean src stream net sm classify plots stats threshold growth imbalance params

clean:
	for i in $(find . -name *.tmp) ; do rm -f $$i; done;
